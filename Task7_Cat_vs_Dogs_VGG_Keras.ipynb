{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Ns2IyTSgh4RdUSn5WOQm7A8ebnYBsejA",
      "authorship_tag": "ABX9TyMwVkeb2uOVtwsrEecHH9AD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adidonner/Machine-Deep-Leap-learning-Python-Based/blob/main/Task7_Cat_vs_Dogs_VGG_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Gf4fBD4CDAS6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "import glob\n",
        "import cv2\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0erM4uhCZVY",
        "outputId": "7056bc7a-8132-40e6-d2c3-ae22984c48ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1467 files belonging to 2 classes.\n",
            "Using 1174 files for training.\n",
            "Found 1467 files belonging to 2 classes.\n",
            "Using 293 files for validation.\n"
          ]
        }
      ],
      "source": [
        "directory = '/content/drive/MyDrive/cats_vs_dogs_data'\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory,\n",
        "    labels='inferred',\n",
        "    batch_size=32,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=True,\n",
        "    seed = 5,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory,\n",
        "    labels='inferred',\n",
        "    batch_size=32,\n",
        "    image_size=(150, 150),\n",
        "    shuffle=False,\n",
        "    seed = 5,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without VGG"
      ],
      "metadata": {
        "id": "Csalj59R1pcg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8Cty47BCXMK",
        "outputId": "8cf55ed0-9896-4a7a-bfef-aa895beb6441"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "37/37 [==============================] - 3s 54ms/step - loss: 8.3469 - accuracy: 0.9608 - val_loss: 1.0662 - val_accuracy: 0.8396\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 1.0352 - accuracy: 0.9651 - val_loss: 1.0289 - val_accuracy: 0.8396\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 4s 85ms/step - loss: 0.9897 - accuracy: 0.9651 - val_loss: 0.9942 - val_accuracy: 0.8396\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 2s 55ms/step - loss: 0.9468 - accuracy: 0.9651 - val_loss: 0.9615 - val_accuracy: 0.8396\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 2s 55ms/step - loss: 0.9061 - accuracy: 0.9651 - val_loss: 0.9309 - val_accuracy: 0.8396\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 2s 57ms/step - loss: 0.8675 - accuracy: 0.9651 - val_loss: 0.9020 - val_accuracy: 0.8396\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 3s 67ms/step - loss: 0.8308 - accuracy: 0.9651 - val_loss: 0.8748 - val_accuracy: 0.8396\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 2s 56ms/step - loss: 0.7960 - accuracy: 0.9651 - val_loss: 0.8492 - val_accuracy: 0.8396\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 2s 54ms/step - loss: 0.7629 - accuracy: 0.9651 - val_loss: 0.8253 - val_accuracy: 0.8396\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 2s 55ms/step - loss: 0.7315 - accuracy: 0.9651 - val_loss: 0.8029 - val_accuracy: 0.8396\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a7ef50ccc70>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Build CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    # Conv2D(64, (3, 3), activation='relu'),\n",
        "    # MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
        "\n",
        "# Plot sample images from each class and display the number of examples\n",
        "# Code to plot images and display class distribution"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# With VGG in Keras Architecture"
      ],
      "metadata": {
        "id": "BFVuQCyx5YJx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take this code (above \"without VGG\") and add to it: Freeze the first 3 layers of the VGG model except for FULLY CONNECTED and the last one. Use GPU and architecture - KERAS. Save the network weights"
      ],
      "metadata": {
        "id": "Zu83E4Wc584W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "from keras.models import Model\n",
        "\n",
        "# Load the VGG16 model without the top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "# Freeze the first 3 layers except for fully connected layers and the last one\n",
        "for layer in base_model.layers[:3]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model by adding the top layers to the modified VGG16 base\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(8, activation='relu')(x)\n",
        "predictions = Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_ds, epochs=10, validation_data=val_ds)\n",
        "\n",
        "# Save the weights\n",
        "model.save_weights('/content/drive/MyDrive/vgg16_frozen_weights_keras.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FxkRA1l3OKv",
        "outputId": "aefb876a-de2c-40a7-c4d5-fe77936acc0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "37/37 [==============================] - 11s 181ms/step - loss: 14.0905 - accuracy: 0.9199 - val_loss: 1.0662 - val_accuracy: 0.8396\n",
            "Epoch 2/10\n",
            "37/37 [==============================] - 7s 179ms/step - loss: 1.0366 - accuracy: 0.9651 - val_loss: 1.0303 - val_accuracy: 0.8396\n",
            "Epoch 3/10\n",
            "37/37 [==============================] - 7s 174ms/step - loss: 0.9925 - accuracy: 0.9651 - val_loss: 0.9963 - val_accuracy: 0.8396\n",
            "Epoch 4/10\n",
            "37/37 [==============================] - 7s 180ms/step - loss: 0.9506 - accuracy: 0.9651 - val_loss: 0.9641 - val_accuracy: 0.8396\n",
            "Epoch 5/10\n",
            "37/37 [==============================] - 7s 177ms/step - loss: 0.9105 - accuracy: 0.9651 - val_loss: 0.9337 - val_accuracy: 0.8396\n",
            "Epoch 6/10\n",
            "37/37 [==============================] - 7s 187ms/step - loss: 0.8723 - accuracy: 0.9651 - val_loss: 0.9050 - val_accuracy: 0.8396\n",
            "Epoch 7/10\n",
            "37/37 [==============================] - 7s 179ms/step - loss: 0.8358 - accuracy: 0.9651 - val_loss: 0.8778 - val_accuracy: 0.8396\n",
            "Epoch 8/10\n",
            "37/37 [==============================] - 8s 191ms/step - loss: 0.8011 - accuracy: 0.9651 - val_loss: 0.8522 - val_accuracy: 0.8396\n",
            "Epoch 9/10\n",
            "37/37 [==============================] - 7s 181ms/step - loss: 0.7680 - accuracy: 0.9651 - val_loss: 0.8283 - val_accuracy: 0.8396\n",
            "Epoch 10/10\n",
            "37/37 [==============================] - 7s 189ms/step - loss: 0.7367 - accuracy: 0.9651 - val_loss: 0.8056 - val_accuracy: 0.8396\n"
          ]
        }
      ]
    }
  ]
}