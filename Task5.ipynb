{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyON5vqRk6zGvwss4F7nAxAt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adidonner/Machine-Deep-Leap-learning-Python-Based/blob/main/Task5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive if necessary\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az0SD64rONJh",
        "outputId": "a6643104-b6ad-47ca-fd91-06a147e2cc76"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the directory path\n",
        "base_dir = \"/content/drive/MyDrive/COCO_dataset\"\n",
        "\n",
        "# Function to count and print the number of files in each subfolder\n",
        "def count_files_in_subfolders(directory):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        if files:\n",
        "            print(f\"Folder: {root[len(base_dir):]}\")\n",
        "            print(f\"Number of files: {len(files)}\")\n",
        "            print(\"------------------------\")\n",
        "\n",
        "# Call the function with the base directory\n",
        "count_files_in_subfolders(base_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxQI4T9rcVmT",
        "outputId": "434197a5-e107-4e24-ef9e-14f84da5d545"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder: /train/cats\n",
            "Number of files: 1475\n",
            "------------------------\n",
            "Folder: /cats_and_dogs_filtered/cats_and_dogs_filtered\n",
            "Number of files: 1\n",
            "------------------------\n",
            "Folder: /cats_and_dogs_filtered/cats_and_dogs_filtered/validation/cats\n",
            "Number of files: 500\n",
            "------------------------\n",
            "Folder: /cats_and_dogs_filtered/cats_and_dogs_filtered/validation/dogs\n",
            "Number of files: 500\n",
            "------------------------\n",
            "Folder: /cats_and_dogs_filtered/cats_and_dogs_filtered/train/dogs\n",
            "Number of files: 1000\n",
            "------------------------\n",
            "Folder: /cats_and_dogs_filtered/cats_and_dogs_filtered/train/cats\n",
            "Number of files: 1000\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write software as a Python senior at Google Collab, GPU\n",
        "Take a COCO dataset Cats Vs Dogs from /content/drive/MyDrive/COCO_dataset/cats_and_dogs_filtered\n",
        "under it there is a train folder with one folder with cat images and one with dog images: /content/drive/MyDrive/COCO_dataset/cats_and_dogs_filtered/cats_and_dogs_filtered/train\n",
        "and validation folder also with subfolders cats and dogs\n",
        "Use 3D KERAS and neural network for to answer\n",
        "Is it a dog or a cat in the picture?\n",
        "test the model\n",
        "Show accuracy and confusion table"
      ],
      "metadata": {
        "id": "bSU7b1a2uUSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the COCO dataset\n",
        "train_data_dir = '/content/drive/MyDrive/COCO_dataset/cats_and_dogs_filtered/cats_and_dogs_filtered/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/COCO_dataset/cats_and_dogs_filtered/cats_and_dogs_filtered/validation'\n",
        "img_size = (150, 150)\n",
        "batch_size = 32\n",
        "\n",
        "# Create a data generator for training images\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "# Create a data generator for validation images\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generate batches of augmented training data\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                    target_size=img_size,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "# Generate batches of validation data\n",
        "validation_generator = val_datagen.flow_from_directory(validation_data_dir,\n",
        "                                                        target_size=img_size,\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "# Build the 3D CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(img_size[0], img_size[1], 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))# Dense was 256\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.samples // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=validation_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "validation_generator.reset()\n",
        "y_pred = model.predict(validation_generator, steps=validation_generator.samples // batch_size, verbose=1)\n",
        "y_true = validation_generator.classes\n",
        "y_pred = np.round(y_pred)\n",
        "\n",
        "# Calculate accuracy\n",
        "# accuracy = accuracy_score(y_true, y_pred)\n",
        "# print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Create confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "HAmTeXNp_lF6",
        "outputId": "2fd7beb3-b6b1-4f4b-9d73-1a142bcdfd6f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "62/62 [==============================] - 26s 372ms/step - loss: 0.7347 - accuracy: 0.5279 - val_loss: 0.7013 - val_accuracy: 0.5050\n",
            "Epoch 2/10\n",
            "62/62 [==============================] - 21s 340ms/step - loss: 0.6779 - accuracy: 0.5620 - val_loss: 0.6553 - val_accuracy: 0.6240\n",
            "Epoch 3/10\n",
            "62/62 [==============================] - 20s 331ms/step - loss: 0.6450 - accuracy: 0.6153 - val_loss: 0.6457 - val_accuracy: 0.6341\n",
            "Epoch 4/10\n",
            "62/62 [==============================] - 22s 354ms/step - loss: 0.6291 - accuracy: 0.6479 - val_loss: 0.6287 - val_accuracy: 0.6401\n",
            "Epoch 5/10\n",
            "62/62 [==============================] - 21s 336ms/step - loss: 0.6061 - accuracy: 0.6611 - val_loss: 0.5911 - val_accuracy: 0.6794\n",
            "Epoch 6/10\n",
            "62/62 [==============================] - 21s 334ms/step - loss: 0.5696 - accuracy: 0.7053 - val_loss: 0.5869 - val_accuracy: 0.6855\n",
            "Epoch 7/10\n",
            "62/62 [==============================] - 23s 366ms/step - loss: 0.5418 - accuracy: 0.7266 - val_loss: 0.5394 - val_accuracy: 0.7288\n",
            "Epoch 8/10\n",
            "62/62 [==============================] - 29s 472ms/step - loss: 0.5150 - accuracy: 0.7480 - val_loss: 0.5506 - val_accuracy: 0.7258\n",
            "Epoch 9/10\n",
            "62/62 [==============================] - 29s 468ms/step - loss: 0.5015 - accuracy: 0.7607 - val_loss: 0.5410 - val_accuracy: 0.7278\n",
            "Epoch 10/10\n",
            "62/62 [==============================] - 21s 335ms/step - loss: 0.5021 - accuracy: 0.7515 - val_loss: 0.5353 - val_accuracy: 0.7349\n",
            "31/31 [==============================] - 3s 96ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d05f58d579c2>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Create confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Confusion Matrix:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 992]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the COCO dataset\n",
        "train_data_dir = '/content/drive/MyDrive/COCO_dataset/cats_and_dogs_filtered/cats_and_dogs_filtered/train'\n",
        "validation_data_dir = '/content/drive/MyDrive/COCO_dataset/cats_and_dogs_filtered/cats_and_dogs_filtered/validation'\n",
        "img_size = (150, 150)\n",
        "batch_size = 32\n",
        "\n",
        "# Create a data generator for training images\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "# Create a data generator for validation images\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Generate batches of augmented training data\n",
        "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
        "                                                    target_size=img_size,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "# Generate batches of validation data\n",
        "validation_generator = val_datagen.flow_from_directory(validation_data_dir,\n",
        "                                                        target_size=img_size,\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "# Build the 3D CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(img_size[0], img_size[1], 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 10\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.samples // batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=validation_generator.samples // batch_size)\n",
        "\n",
        "# Evaluate the model\n",
        "validation_generator.reset()\n",
        "y_pred = model.predict(validation_generator, steps=validation_generator.samples // batch_size, verbose=1)\n",
        "y_true = validation_generator.classes\n",
        "y_pred = np.round(y_pred)\n",
        "\n",
        "# Calculate accuracy\n",
        "# accuracy = accuracy_score(y_true, y_pred)\n",
        "# print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "\n",
        "# Create confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "XfI2IZrd17aq",
        "outputId": "fc560078-d7d3-4f7e-a6a1-229b5d4753e3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "62/62 [==============================] - 27s 403ms/step - loss: 0.7459 - accuracy: 0.4812 - val_loss: 0.6947 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "62/62 [==============================] - 21s 342ms/step - loss: 0.6893 - accuracy: 0.5574 - val_loss: 0.6790 - val_accuracy: 0.5837\n",
            "Epoch 3/10\n",
            "62/62 [==============================] - 23s 368ms/step - loss: 0.6696 - accuracy: 0.5945 - val_loss: 0.6673 - val_accuracy: 0.5857\n",
            "Epoch 4/10\n",
            "62/62 [==============================] - 23s 380ms/step - loss: 0.6486 - accuracy: 0.6321 - val_loss: 0.6332 - val_accuracy: 0.6593\n",
            "Epoch 5/10\n",
            "62/62 [==============================] - 21s 344ms/step - loss: 0.6272 - accuracy: 0.6585 - val_loss: 0.7248 - val_accuracy: 0.6280\n",
            "Epoch 6/10\n",
            "62/62 [==============================] - 24s 385ms/step - loss: 0.6047 - accuracy: 0.6784 - val_loss: 0.5789 - val_accuracy: 0.6855\n",
            "Epoch 7/10\n",
            "62/62 [==============================] - 22s 351ms/step - loss: 0.5627 - accuracy: 0.7282 - val_loss: 0.5860 - val_accuracy: 0.6774\n",
            "Epoch 8/10\n",
            "62/62 [==============================] - 23s 376ms/step - loss: 0.5772 - accuracy: 0.6941 - val_loss: 0.5687 - val_accuracy: 0.6986\n",
            "Epoch 9/10\n",
            "62/62 [==============================] - 21s 345ms/step - loss: 0.5316 - accuracy: 0.7358 - val_loss: 0.5652 - val_accuracy: 0.7177\n",
            "Epoch 10/10\n",
            "62/62 [==============================] - 22s 354ms/step - loss: 0.5121 - accuracy: 0.7541 - val_loss: 0.5378 - val_accuracy: 0.7349\n",
            "31/31 [==============================] - 3s 103ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-81e784316196>\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# Create confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mconf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Confusion Matrix:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 992]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "validation_dogs_dir = '/content/drive/MyDrive/COCO_dataset/cats_and_dogs_filtered/cats_and_dogs_filtered/train/dogs'\n",
        "\n",
        "# List all files in the directory\n",
        "all_files = os.listdir(validation_dogs_dir)\n",
        "\n",
        "# Filter only files with valid image extensions (e.g., '.jpg', '.png')\n",
        "image_files = [file for file in all_files if file.lower().endswith(('.jpg', '.png'))]\n",
        "\n",
        "# Get the number of images\n",
        "num_images = len(image_files)\n",
        "\n",
        "print(\"Number of images in validation/dogs directory:\", num_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1KPM_EX3m2v",
        "outputId": "a39a4eb4-0fa1-47ef-d49b-f04fd8016f91"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in validation/dogs directory: 1000\n"
          ]
        }
      ]
    }
  ]
}